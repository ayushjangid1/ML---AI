import cv2
hog=cv2.HOGDescriptor()






hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())







vid=cv2.VideoCapture(0)
while True:
    flag,img=vid.read()
    if flag:
        img_gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
        bounding_boxes,weights=hog.detectMultiScale(img_gray,winStride=(10,10))
        #for detect the whole person and draw yhe rectangle on it body
        for x,y,w,h in bounding_boxes:
            cv2.rectangle(img,pt1=(x,y),pt2=(x+w,y+h),color=(0,0,255),thickness=4)
        #sleep(0.1)
        cv2.imshow('Preview',img)
        key=cv2.waitKey(1)
        if key==ord('q'):
            break
cv2.destroyAllWindows()
vid.release()








import nltk
import pyttsx3
import speech_recognition as sp






spEng=pyttsx3.init()
spEng.setProperty('rate',60)
spEng.say('Talk-to-ChatGPT is a Google Chrome and Microsoft Edge extension that allows users to talk with the ChatGPT AI using their voice (speech recognition), and listen to the bots answer with a voice (text-to-speech), rather than just by typing. With this tool, users can speak to the AI and receive spoken responses, making the interaction feel more natural and conversational. This could be useful in a variety of settings where it would be helpful to have a more human-like interaction with an AI. As of version 2.6, we now support ElevenLabs API integration, which means you can create your own voices for text-to-speech!')
spEng.runAndWait()








recognizer=sp.Recognizer()
with sp.Microphone() as mic:
    print('Say',end='')
    audio = recognizer.listen(mic,phrase_time_limit=1)
    try:
        text=recognizer.recognize_google(audio)
        print(text)
    except Exception as err:
        print('\ncould not recognise')







with sp.Microphone() as mic:
    print('Say:',end='')
    audio=recognizer.listen(mic)
    try:
        text=recognizer.recognize_google(audio)
        print(text)
        spEng.say(text)
        spEng.runAndWait()
    except Exception as err:
        print('could not recognise')